{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Usar a detecção de faces via SDK do Python"
      ],
      "metadata": {
        "id": "TM7SOiVcIvTr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instalando a biblioteca em Python para detecção de faces\n"
      ],
      "metadata": {
        "id": "3OWDpKUZB2an"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Execute somente ao iniciar o notebook"
      ],
      "metadata": {
        "id": "jZHa3bDNCfEi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install --upgrade azure-cognitiveservices-vision-face"
      ],
      "metadata": {
        "id": "B2w342isB0ai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importando as bibliotecas necessárias"
      ],
      "metadata": {
        "id": "NhaqCWm6CkBt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "import io\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import uuid\n",
        "import requests\n",
        "from urllib.parse import urlparse\n",
        "from io import BytesIO\n",
        "# To install this module, run:\n",
        "# python -m pip install Pillow\n",
        "from PIL import Image, ImageDraw\n",
        "from azure.cognitiveservices.vision.face import FaceClient\n",
        "from msrest.authentication import CognitiveServicesCredentials\n",
        "from azure.cognitiveservices.vision.face.models import TrainingStatusType, Person, QualityForRecognition"
      ],
      "metadata": {
        "id": "0GaNW25pCzUk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configurando variáveis necessárias"
      ],
      "metadata": {
        "id": "6TY9kIJYC6BX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui vamos precisar de uma chave e do ponto final para utilizar a api. Para isso, acesse a página do recurso e clique em \"Clique aqui para gerir chaves\". Na próxima página, copie uma das chaves e o ponto final."
      ],
      "metadata": {
        "id": "PrBT4W5rDTN4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## LEMBRE-SE DE NÃO COMPARTILHAR ESSE ARQUIVO COM A CHAVE E O PONTO FINAL\n",
        "\n",
        "## Chave de api\n",
        "KEY = \"1cfbbe187ae94a0780deec58fe285c03\"\n",
        "\n",
        "# Ponto final\n",
        "ENDPOINT = \"https://laboratorioai900faceapi.cognitiveservices.azure.com/\"\n",
        "\n",
        "# Base url for the Verify and Facelist/Large Facelist operations\n",
        "IMAGE_BASE_URL = 'https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/Face/images/'"
      ],
      "metadata": {
        "id": "2yN4_xemC97q"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui criamos um grupo de pessoas para podermos gerenciá-lo."
      ],
      "metadata": {
        "id": "CB6DcN_VEzAM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SOURCE_PERSON_GROUP_ID deve ser minúsculo e alfanumérico. por exemplo, 'mygroupname'.\n",
        "PERSON_GROUP_ID = str(uuid.uuid4())\n",
        "TARGET_PERSON_GROUP_ID = str(uuid.uuid4())\n",
        "\n",
        "# Autenticando para acesso à API\n",
        "face_client = FaceClient(ENDPOINT, CognitiveServicesCredentials(KEY))"
      ],
      "metadata": {
        "id": "U8t-b7LlEzTI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Criando o grupo de pessoas:"
      ],
      "metadata": {
        "id": "rnCXbE83FVnp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Criando um grupo de pessoas vazio\n",
        "print('Grupo de pessoas:', PERSON_GROUP_ID)\n",
        "face_client.person_group.create(person_group_id=PERSON_GROUP_ID, name=PERSON_GROUP_ID, recognition_model='recognition_04')\n",
        "\n",
        "# Definindo Mulher\n",
        "woman = face_client.person_group_person.create(PERSON_GROUP_ID, name=\"Woman\")\n",
        "# Definindo Homem\n",
        "man = face_client.person_group_person.create(PERSON_GROUP_ID, name=\"Man\")\n",
        "# Definindo Criança\n",
        "child = face_client.person_group_person.create(PERSON_GROUP_ID, name=\"Child\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "fFySPryBFjTk",
        "outputId": "7c7b6e72-e3a0-4f59-9245-bfabc136a73d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grupo de pessoas: 246e6336-0ef2-4969-8d02-8380a8e77ed0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "APIErrorException",
          "evalue": "(InvalidRequest) Invalid request has been sent.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAPIErrorException\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-2fcbfbdb8edd>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Criando um grupo de pessoas vazio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Grupo de pessoas:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPERSON_GROUP_ID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mface_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperson_group\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperson_group_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPERSON_GROUP_ID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPERSON_GROUP_ID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecognition_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'recognition_04'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Definindo Mulher\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/azure/cognitiveservices/vision/face/operations/_person_group_operations.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, person_group_id, name, user_data, recognition_model, custom_headers, raw, **operation_config)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAPIErrorException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deserialize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mraw\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAPIErrorException\u001b[0m: (InvalidRequest) Invalid request has been sent."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusão"
      ],
      "metadata": {
        "id": "VuwDO3-FIq0Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O erro acima foi gerado pois para utilizar a detecção de Faces via Api e SDK's é necessário ser cliente ou um dos parceiros gerenciados pela Microsoft. Para ser aprovado, é necessário enviar o seguinte formulário e esperar a aprovação: [http://aka.ms/facerecognition](http://aka.ms/facerecognition)\n",
        "\n",
        "Saiba mais sobre a limitação de API: [Recursos de Acesso Limitado para os serviços de IA do Azure](https://learn.microsoft.com/pt-br/azure/ai-services/cognitive-services-limited-access)"
      ],
      "metadata": {
        "id": "uY_3WJGgI5qs"
      }
    }
  ]
}